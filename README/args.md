# Argumentos Avanzados

## Â¿QuÃ© son los argumentos?

Los **argumentos** son parÃ¡metros tÃ©cnicos que controlan el comportamiento del motor de traducciÃ³n. Estos ajustes finos permiten optimizar el rendimiento y la calidad segÃºn tus necesidades especÃ­ficas.

## Argumentos principales

### ğŸ”§ **--config [archivo]**

**Â¿QuÃ© hace?**  
Especifica el archivo de configuraciÃ³n de prompts que guiarÃ¡ las traducciones.

**UbicaciÃ³n:** `PROMTS/[archivo].yaml`

**Ejemplos:**
- `--config 1-completions-PROMT.yaml` - Prompts bÃ¡sicos
- `--config 2-completions-PROMT.yaml` - Prompts mejorados  
- `--config 3-completions-LLAMA-models.yaml` - EspecÃ­fico para Llama

### ğŸ”„ **--lm-compat [protocolo]**

**Â¿QuÃ© hace?**  
Define el protocolo de comunicaciÃ³n con el modelo de IA.

**Opciones disponibles:**
- `completions` - Para modelos que usan completions API
- `chat` - Para modelos que usan chat API (recomendado)
- `auto` - DetecciÃ³n automÃ¡tica

**RecomendaciÃ³n:** Usa `chat` para la mayorÃ­a de modelos modernos.

### ğŸ“¦ **--batch-size [nÃºmero]**

**Â¿QuÃ© hace?**  
Controla cuÃ¡ntos textos se envÃ­an al modelo en cada peticiÃ³n.

**Valores tÃ­picos:**
- `5-10` - Para modelos grandes y hardware limitado
- `15-25` - Para modelos medianos (recomendado)
- `30-50` - Para modelos pequeÃ±os y hardware potente

**Impacto:**
- **Valor alto**: MÃ¡s rÃ¡pido, pero consume mÃ¡s memoria
- **Valor bajo**: MÃ¡s lento, pero mÃ¡s estable

### â±ï¸ **--timeout [segundos]**

**Â¿QuÃ© hace?**  
Tiempo mÃ¡ximo que el sistema espera una respuesta del modelo antes de dar error.

**Valores recomendados:**
- `30-60` - Para modelos pequeÃ±os y rÃ¡pidos
- `60-120` - Para modelos medianos (estÃ¡ndar)
- `120-300` - Para modelos grandes o hardware lento

### ğŸ” **--max-tokens [nÃºmero]**

**Â¿QuÃ© hace?**  
LÃ­mite mÃ¡ximo de tokens (palabras) que puede generar el modelo por respuesta.

**Valores tÃ­picos:**
- `256` - Para textos cortos (mensajes, nombres)
- `512` - Para textos medianos (briefings)
- `1024` - Para textos largos (narrativa completa)

### ğŸŒ¡ï¸ **--temperature [0.0-2.0]**

**Â¿QuÃ© hace?**  
Controla la creatividad vs consistencia del modelo.

**Valores recomendados:**
- `0.1-0.3` - Muy consistente, traducciones tÃ©cnicas
- `0.4-0.7` - Equilibrio (recomendado para DCS)
- `0.8-1.2` - MÃ¡s creativo, traducciones literarias

### ğŸ¯ **--top-p [0.1-1.0]**

**Â¿QuÃ© hace?**  
Controla la variabilidad en la selecciÃ³n de palabras.

**Valores tÃ­picos:**
- `0.1-0.3` - Muy predecible
- `0.4-0.6` - Equilibrado (recomendado)
- `0.7-0.9` - MÃ¡s variado

## Configuraciones por preset

### âš¡ **Preset Ligero**
```
--config 1-completions-PROMT.yaml
--lm-compat chat
--batch-size 30
--timeout 60
--max-tokens 512
--temperature 0.3
--top-p 0.5
```

### âš–ï¸ **Preset Balanceado**
```
--config 2-completions-PROMT.yaml
--lm-compat chat
--batch-size 20
--timeout 90
--max-tokens 512
--temperature 0.5
--top-p 0.6
```

### ğŸ”¥ **Preset Pesado**
```
--config 3-completions-LLAMA-models.yaml
--lm-compat chat
--batch-size 10
--timeout 180
--max-tokens 1024
--temperature 0.7
--top-p 0.7
```

## Argumentos especiales

### ğŸš€ **--parallel [nÃºmero]**

**Â¿QuÃ© hace?**  
Controla cuÃ¡ntas peticiones simultÃ¡neas puede hacer al modelo.

**Cuidado:** Valores altos pueden saturar el modelo o causar errores.

### ğŸ”„ **--retry-attempts [nÃºmero]**

**Â¿QuÃ© hace?**  
CuÃ¡ntas veces reintenta una traducciÃ³n si falla.

**Recomendado:** 2-3 intentos para estabilidad.

### ğŸ“ **--log-level [nivel]**

**Â¿QuÃ© hace?**  
Controla la cantidad de informaciÃ³n en los logs.

**Opciones:**
- `ERROR` - Solo errores crÃ­ticos
- `INFO` - InformaciÃ³n general (recomendado)
- `DEBUG` - InformaciÃ³n detallada para diagnosticar

## OptimizaciÃ³n por tipo de contenido

### ğŸ“‹ **Textos tÃ©cnicos** (procedimientos, checklists)
```
--temperature 0.2
--top-p 0.3
--max-tokens 256
```

**Prioriza:** Consistencia y precisiÃ³n

### ğŸ“– **Narrativa** (briefings, historias)
```
--temperature 0.6
--top-p 0.7
--max-tokens 1024
```

**Prioriza:** Naturalidad y fluidez

### âš¡ **Textos cortos** (mensajes, nombres)
```
--batch-size 50
--timeout 30
--max-tokens 128
```

**Prioriza:** Velocidad de procesamiento

## ResoluciÃ³n de problemas con argumentos

### âŒ **"Timeout errors frecuentes"**
- **Aumentar** `--timeout`
- **Reducir** `--batch-size`
- **Verificar** que el modelo no estÃ© sobrecargado

### âŒ **"Traducciones inconsistentes"**
- **Reducir** `--temperature` (0.1-0.3)
- **Reducir** `--top-p` (0.2-0.4)
- **Usar prompts mÃ¡s especÃ­ficos**

### âŒ **"Traducciones cortadas"**
- **Aumentar** `--max-tokens`
- **Reducir** `--batch-size`
- **Verificar lÃ­mites del modelo**

### âŒ **"Muy lento"**
- **Aumentar** `--batch-size`
- **Reducir** `--timeout`
- **Usar modelo mÃ¡s pequeÃ±o**

### âŒ **"Errores de memoria"**
- **Reducir** `--batch-size`
- **Reducir** `--max-tokens`
- **Cerrar otros programas**

## ConfiguraciÃ³n personalizada

### ğŸ› ï¸ **Para crear tu configuraciÃ³n:**

1. **Comienza** con un preset base
2. **Modifica** 1-2 argumentos a la vez
3. **Prueba** con una campaÃ±a pequeÃ±a
4. **Ajusta** segÃºn los resultados
5. **Guarda** como perfil personalizado

### ğŸ“Š **MÃ©tricas para evaluar:**

- **Velocidad**: Tiempo total de traducciÃ³n
- **Calidad**: Naturalidad y precisiÃ³n
- **Estabilidad**: Frecuencia de errores
- **Consumo**: Uso de memoria y CPU

## Argumentos experimentales

### âš ï¸ **Usar con precauciÃ³n:**

- `--experimental-mode` - Funciones beta
- `--force-gpu` - Forzar uso de GPU
- `--memory-limit` - LÃ­mite de memoria

**Nota:** Estos argumentos pueden cambiar o ser removidos en futuras versiones.

## Recomendaciones por experiencia

### ğŸ‘¶ **Principiantes:**
- **Usa presets** por defecto sin modificar
- **No toques** temperatura ni top-p inicialmente
- **Solo ajusta** batch-size y timeout si hay problemas

### ğŸ‘¨â€ğŸ’¼ **Usuarios regulares:**
- **Personaliza** batch-size segÃºn tu hardware
- **Ajusta timeout** segÃºn velocidad del modelo
- **Experimenta** con temperature para diferentes tipos de texto

### ğŸ‘¨â€ğŸ’» **Usuarios avanzados:**
- **Crea configuraciones especÃ­ficas** para cada tipo de campaÃ±a
- **Optimiza** todos los parÃ¡metros segÃºn tus necesidades
- **Contribuye** con configuraciones exitosas para la comunidad